{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2edba47-9e2e-476e-9f2f-fb177b329063",
   "metadata": {},
   "source": [
    "<image src=\"./images/dashboard.jpg\" alt=\"A car dashboard with lots of new technical features.\" width=\"600\">\n",
    "\n",
    "You're working for a well-known car manufacturer who is looking at implementing LLMs into vehicles to provide guidance to drivers. You've been asked to experiment with integrating car manuals with an LLM to create a context-aware chatbot. They hope that this context-aware LLM can be hooked up to a text-to-speech software to read the model's response aloud.\n",
    "\n",
    "As a proof of concept, you'll integrate several pages from a car manual that contains car warning messages and their meanings and recommended actions. This particular manual, stored as an HTML file, `mg-zs-warning-messages.html`, is from an MG ZS, a compact SUV. Armed with your newfound knowledge of LLMs and LangChain, you'll implement Retrieval Augmented Generation (RAG) to create the context-aware chatbot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61baf413-6464-4c1c-a52d-b3764c124602",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 52,
    "lastExecutedAt": 1748687242303,
    "lastExecutedByKernel": "e1a383ba-def3-4fc4-9a5a-37feb3905837",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Set your API key to a variable\nimport os\nopenai_api_key = os.environ[\"OPENAI_API_KEY\"]\n\n# Import the required packages\nfrom langchain_core.prompts import ChatPromptTemplate\nfrom langchain_openai import ChatOpenAI\nfrom langchain_community.document_loaders import UnstructuredHTMLLoader\nfrom langchain_openai import OpenAIEmbeddings\nfrom langchain_core.runnables import RunnablePassthrough\nfrom langchain_text_splitters import RecursiveCharacterTextSplitter\nfrom langchain_chroma import Chroma"
   },
   "outputs": [],
   "source": [
    "# Import the required packages\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_community.document_loaders import UnstructuredHTMLLoader\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_chroma import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bed58c70-1315-409c-a590-a4c7af3cad80",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 47,
    "lastExecutedAt": 1748687242351,
    "lastExecutedByKernel": "e1a383ba-def3-4fc4-9a5a-37feb3905837",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Load the HTML as a LangChain document loader\nloader = UnstructuredHTMLLoader(file_path=\"data/mg-zs-warning-messages.html\")\ncar_docs = loader.load()"
   },
   "outputs": [],
   "source": [
    "# Load the HTML as a LangChain document loader\n",
    "loader = UnstructuredHTMLLoader(file_path=\"data/mg-zs-warning-messages.html\")\n",
    "car_docs = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fbcd5be-4b6d-4993-b871-a5f18ad9b867",
   "metadata": {},
   "source": [
    "Split the Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "423ab3be-fe15-4316-91b2-12f0e114abe1",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 48,
    "lastExecutedAt": 1748687242399,
    "lastExecutedByKernel": "e1a383ba-def3-4fc4-9a5a-37feb3905837",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "splitter = RecursiveCharacterTextSplitter(\n    chunk_size=1000,\n    chunk_overlap=200,\n)\n\nchunks = splitter.split_documents(car_docs)\nprint(chunks[0].page_content)",
    "outputsMetadata": {
     "0": {
      "height": 164,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning Message Procedure Cruise Control Fault Indicates that the cruise control system has detected a fault. Please consult an MG Authorised Repairer as soon as possible. Active Speed Limiter Fault Indicates that the active speed limit system has detected a fault. Contact an MG Authorised Repairer as soon as possible. Engine Coolant Temperature High High engine coolant temperature could result in severe damage. As soon as conditions permit, safely stop the vehicle and switch off the engine and contact an MG Authorised Repairer immediately. Engine Coolant Temperature Sensor Fault Indicates that the engine coolant temperature sensor has failed. As soon as conditions permit, safely stop the vehicle and switch off the engine and contact an MG Authorised Repairer immediately.\n"
     ]
    }
   ],
   "source": [
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    ")\n",
    "\n",
    "chunks = splitter.split_documents(car_docs)\n",
    "print(chunks[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f9a394-8637-41dc-bd4b-529aa0044b9e",
   "metadata": {},
   "source": [
    "Store the Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ca2fcc5-686f-471c-a7cc-9d122dde3b39",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 1705,
    "lastExecutedAt": 1748687244104,
    "lastExecutedByKernel": "e1a383ba-def3-4fc4-9a5a-37feb3905837",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "embedding_function = OpenAIEmbeddings(\n    api_key=openai_api_key\n)  \n\nvectorstore = Chroma.from_documents(\n    documents=car_docs,\n    embedding=embedding_function\n)"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/n5/mm68ph654jj0kwghx08j70l40000gp/T/ipykernel_11304/2457627876.py:1: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_function = HuggingFaceEmbeddings(\n",
      "/Users/crypticsy/anaconda3/envs/genai/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import error: No module named 'triton'\n"
     ]
    }
   ],
   "source": [
    "embedding_function = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    ")\n",
    "\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=car_docs,\n",
    "    embedding=embedding_function\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d3c820-f013-4cd3-a130-49038e5e478a",
   "metadata": {},
   "source": [
    "Create a retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca3af096-f8a4-475b-a254-71bcf18d34de",
   "metadata": {
    "executionCancelledAt": 1748687244100
   },
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\":1}  # Number of documents to retrieve\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f67a9be-022d-497f-92d9-ec89f6b678af",
   "metadata": {},
   "source": [
    "Initialize the LLM and Prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea1fc64-2799-4d49-a516-a26ee0a10f22",
   "metadata": {
    "executionCancelledAt": 1748687244101
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/n5/mm68ph654jj0kwghx08j70l40000gp/T/ipykernel_11304/722147542.py:3: LangChainDeprecationWarning: The class `Ollama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaLLM``.\n",
      "  llm = Ollama(model=\"llama3\")\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "\n",
    "# Using Ollama applications within the operating system\n",
    "llm = Ollama(model=\"llama3\")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\" You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. \n",
    "                                              If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
    "                                              \\nQuestion: {question} \n",
    "                                              \\nContext: {context} \n",
    "                                              \\nAnswer:\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e28b19b-b6f2-4669-a973-1da1e23e8f4a",
   "metadata": {},
   "source": [
    "Defining the RAG Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f4a878c8-16c6-4e46-9f50-e734904f05a3",
   "metadata": {
    "executionCancelledAt": 1748687244102
   },
   "outputs": [],
   "source": [
    "from langchain.schema import StrOutputParser\n",
    "\n",
    "rag_chain = (\n",
    "    {\n",
    "        \"context\": retriever,\n",
    "        \"question\": RunnablePassthrough()\n",
    "    }\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a641c3-bbfa-441e-a26e-69207f6eaa6d",
   "metadata": {},
   "source": [
    "Invoke RAG chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "681e9310-3209-4811-ac0e-5605dfd1e007",
   "metadata": {
    "executionCancelledAt": 1748687244103
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Gasoline Particular Filter Full warning means that your gasoline particulate filter is full and needs to be replaced or cleaned. You should consult an MG Authorised Repairer as soon as possible to resolve the issue.\n"
     ]
    }
   ],
   "source": [
    "user_query = \"The Gasoline Particular Filter Full warning has appeared. What does this mean and what should I do about it?\"\n",
    "\n",
    "result = rag_chain.invoke(user_query)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Welcome to DataCamp Workspaces.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "genai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
