{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "680c5a84",
   "metadata": {},
   "source": [
    "Vector RAG limitations\n",
    "- Document embedding captures semantic meaning but struggles to capture themes and relationships between entities in the document corpus.\n",
    "- As the volume of the database grows, the retrieval process can become less efficient, as the computational load increases with the search space.\n",
    "- Vector RAG systems don't easily accommodate structured or diverse data, which are harder to embed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36db29ce",
   "metadata": {},
   "source": [
    "Graph databases\n",
    "- Graphs are great at representing and storing diverse and interconnected information in a structured manner.\n",
    "- Graphs are represented as nodes and edges, which can capture complex relationships and hierarchies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6bc006b",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b8bc5a",
   "metadata": {},
   "source": [
    "Creating Graph Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09638019",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WikipediaLoader \n",
    "from langchain_text_splitters import TokenTextSplitter\n",
    "\n",
    "raw_documents = WikipediaLoader(query=\"large language model\").load()\n",
    "text_splitter = TokenTextSplitter (chunk_size=100, chunk_overlap=20)\n",
    "documents = text_splitter.split_documents(raw_documents[:3])\n",
    "\n",
    "print (documents [0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026c1224",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
    "\n",
    "llm = ChatOpenAI(api_key=\"...\", temperature=0, model_name=\"gpt-40-mini\")\n",
    "Llm_transformer = LLMGraphTransformer(llm=llm)\n",
    "\n",
    "graph_documents = llm_transformer.convert_to_graph_documents(documents)\n",
    "print (graph_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38dea553",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11fb477",
   "metadata": {},
   "source": [
    "Instantiating the Neo4j database "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf0039a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.graphs import Neo4jGraph\n",
    "\n",
    "graph = Neo4jGraph(url=\"bolt://Localhost:7687\", username=\"neo4j\", password=\"...\")\n",
    "\n",
    "import os\n",
    "\n",
    "url = os. environ[\"NE04J_URI\"]\n",
    "user = os. environ [\"NE04J_USERNAME\"]\n",
    "password = os.environ[\"NE04J_PASSWORD\" ]\n",
    "graph = Neo4jGraph(url=url, username=user, password=password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973989ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.add_graph_documents(\n",
    "  graph_documents, \n",
    "  include_source=True, # Link nodes to their source documents with MENTIONS edge\n",
    "  baseEntityLabel=True, # add __Entity__ label to each node\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d01677",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(graph.get_schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0696ef9",
   "metadata": {},
   "source": [
    "Quering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f209e388",
   "metadata": {},
   "source": [
    "<image src=\"./images/quering_with_neo4js.png\" alt=\"RAG Workflow\" width=\"600\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae093ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = graph. query (\"\"\"\n",
    "MATCH (gpt4:Model {id: \"Gpt-4\"})-[:DEVELOPED_BY]->(org:0rganization)\n",
    "RETURN org\n",
    "\"\"\")\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1139dc",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404e179a",
   "metadata": {},
   "source": [
    "Combining everythig together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16bcae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chains.graph_qa.cypher import GraphCypherQAChain\n",
    "\n",
    "chain = GraphCypherQAChain.from_llm(\n",
    "  llm=llm,\n",
    "  graph=graph, \n",
    "  verbose=True\n",
    ")\n",
    "\n",
    "result = chain.invoke({\"query\": \"What is the most accurate model?\"})\n",
    "\n",
    "print(f\"Final answer: {result['result']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fde8712",
   "metadata": {},
   "source": [
    "Improving graph retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30aac3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chains.graph_qa.cypher import GraphCypherQAChain\n",
    "\n",
    "llm = ChatOpenAI (api_key=\"...\", model=\"gpt-40-mini\", temperature=0)\n",
    "\n",
    "chain = GraphCypherQAChain.from_llm(\n",
    "  graph=graph, \n",
    "  llm=llm, \n",
    "  exclude_types=[\"Concept\"], \n",
    "  verbose=True,\n",
    "  validate_cypher=True # Detects nodes and relationships + Determines the directions of a relationship + checks the graph schema + update the direction of relationships if needed\n",
    ")\n",
    "\n",
    "print(graph.get_schema)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
